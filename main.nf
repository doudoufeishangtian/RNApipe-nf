#!/usr/bin/env nextflow
/*
================================================================================
--------------------------------------------------------------------------------
			NEXTFLOW pipeline for RNAseq analysis
			provided by @zhangdongqin2@126.com 
--------------------------------------------------------------------------------
================================================================================
RNAseq pipeline is a quick and easy pipeline deploy on linux/Mac system.
This pipeline is supported run on specified conda environment.
You can use environment.yml to create a conda environment for this pipeline.
You can run this pipeline on local conda env by < -with-conda /path/to/conda/env >
This pipeline is desiged and implement by Zhang.DQ < zhangdongqin2@126.com >
Pipeline visualization is supported by nf-core
================================================================================
*/
ANSI_RESET = "\u001B[0m";
ANSI_BLACK = "\u001B[30m";
ANSI_RED = "\u001B[31m";
ANSI_GREEN = "\u001B[32m";
ANSI_YELLOW = "\u001B[33m";
ANSI_BLUE = "\u001B[34m";
ANSI_PURPLE = "\u001B[35m";
ANSI_CYAN = "\u001B[36m";
ANSI_WHITE = "\u001B[37m";
def print_red = {  str -> ANSI_RED + str + ANSI_RESET }
def print_black = {  str -> ANSI_BLACK + str + ANSI_RESET }
def print_green = {  str -> ANSI_GREEN + str + ANSI_RESET }
def print_yellow = {  str -> ANSI_YELLOW + str + ANSI_RESET }
def print_blue = {  str -> ANSI_BLUE + str + ANSI_RESET }
def print_cyan = {  str -> ANSI_CYAN + str + ANSI_RESET }
def print_purple = {  str -> ANSI_PURPLE + str + ANSI_RESET }
def print_white = {  str -> ANSI_WHITE + str + ANSI_RESET }

nextflow.enable.dsl = 2

def helpMessage() {
    log.info nfcoreHeader()
    log.info"""
    A Nextflow-based RNAseq Analysis Pipeline,version:$params.version
    Usage:

    The typical command for running the pipeline is as follows:

    nextflow run main.nf --genome genome.fa --gtf genes.gtf --hisat2_index /index/genome --reads 'reads/*_{1,2}.fq.gz'

    Required arguments:
      --reads        [file]           Path to input data (must be surrounded with quotes) < 'reads/*_{1,2}.fq.gz' >
      --genome       [file]           Path to reference genome fasta file < /home/db/genome.fa >
      --gtf          [file]           Path to reference genome GTF file < /home/db/genes.gtf >          
      --hisat2_index [path]           Path to reference HISAT2 index path name < /home/db/index/genome > 

    Optional arguments:
      --help          [str]           Help information for RNAseq pipeline
      --cpus          [int]           Cpu cores for pipeline , default is 6, you can specify core numbers with < --cpu 8 >
      --salmon_index [path]           Path to salmon index for salmon quant. Default is false, program will denovo generate salmon index.
      --outdir       [path]           Path to analysis results directory ,defalut is < ./results >.
      --single_end   [bool]           Specifies that the input is single-end reads

    Other Options:
      --debug        [bool]           Flag to run only specific fusion tool/s and not the whole pipeline. Only works on tool flags.
      --outdir       [file]           The output directory where the results will be saved
      --email       [email]           Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits
      --email_on_fail[email]          Same as --email, except only send mail if the workflow is not successful
      --max_multiqc_email_size [str]  Theshold size for MultiQC report to be attached in notification email. If file generated by pipeline exceeds the threshold, it will not be attached (Default: 25MB)
      -name [str]                     Name for the pipeline run. If not specified, Nextflow will automatically generate a random mnemonic

    AWSBatch options:
      --awsqueue [str]                The AWSBatch JobQueue that needs to be set when running on AWSBatch
      --awsregion [str]               The AWS Region for your AWS Batch job to run on
      --awscli [str]                  Path to the AWS CLI tool
    """.stripIndent()
}



def nfcoreHeader() {
    // Log colors ANSI codes
    c_black = params.monochrome_logs ? '' : "\033[0;30m";
    c_blue = params.monochrome_logs ? '' : "\033[0;34m";
    c_cyan = params.monochrome_logs ? '' : "\033[0;36m";
    c_dim = params.monochrome_logs ? '' : "\033[2m";
    c_green = params.monochrome_logs ? '' : "\033[0;32m";
    c_purple = params.monochrome_logs ? '' : "\033[0;35m";
    c_reset = params.monochrome_logs ? '' : "\033[0m";
    c_white = params.monochrome_logs ? '' : "\033[0;37m";
    c_yellow = params.monochrome_logs ? '' : "\033[0;33m";

    return """    -${c_dim}--------------------------------------------------${c_reset}-
                                            ${c_green},--.${c_black}/${c_green},-.${c_reset}
    ${c_blue}        ___     __   __   __   ___     ${c_green}/,-._.--~\'${c_reset}
    ${c_blue}  |\\ | |__  __ /  ` /  \\ |__) |__         ${c_yellow}}  {${c_reset}
    ${c_blue}  | \\| |       \\__, \\__/ |  \\ |___     ${c_green}\\`-._,-`-,${c_reset}
                                            ${c_green}`._,._,\'${c_reset}
    ${c_purple}  nf-core/rnaseq_pipeline/@zhangdongqin2@126.com v${workflow.manifest.version}${c_reset}
    -${c_dim}--------------------------------------------------${c_reset}-
    """.stripIndent()
}

// define a help params for pipeline
if (params.help) exit 0, helpMessage()	
if ( params.genome )        {      genome_fasta = file(params.genome)   } else { exit 1, 'ERROR:Genome fasta file not specified!' }
if ( params.gtf )           {      gtf          = file( params.gtf  )   } else { exit 1, 'ERROR:Genome gtf file not specified!'   }
//if ( params.hisat2_index )  {  hisat2_index     = params.hisat2_index 					  } else { exit 1, 'ERROR:Hisat2 index not specified!'   }

//println hisat2_index

//hisat2_index = params.hisat2_index ? Channel.value(file(params.hisat2_index)).ifEmpty{exit 1, "hisat2 index not found: ${params.hisat2_index}" } : hisat2_index
//hisat2_index = hisat2_index.dump(tag:'hisat2_index')
//myFileChannel = Channel.fromPath( params.hisat2_index )


if (params.reads){ raw_reads = Channel.fromFilePairs(params.reads,size: params.single_end ? 1 : 2 )
										 .ifEmpty{ exit 1, "ERROR:Cannot find any reads matching: ${params.reads}\nNB: Path needs to be enclosed in quotes!" }
				   reads_fastp  = Channel.fromFilePairs(params.reads,size: params.single_end ? 1 : 2 )
}

log.info nfcoreHeader()
log.info print_yellow("=====================================")
log.info print_yellow("Fastq file extension:           ") + print_green(params.reads)
log.info print_yellow("Output directory:               ") + print_green(params.outdir)
log.info print_yellow("Genome sequence file:           ") + print_green(params.genome)
log.info print_yellow("HISAT2 index path:              ") + print_green(params.hisat2_index)
log.info print_yellow("Genome annotation file:   	   ") + print_green(params.gtf)
log.info print_yellow("Cpu core number:                ") + print_green(params.cpus)
log.info print_yellow("=====================================")
/*
println	gtf
println genome_fasta
println hisat2_index*/
//println reads_fastqc
//println reads_fastp

/*================================================================================
            Define module functions for RNAseq pipeline
--------------------------------------------------------------------------------
==================================================================================
*/
/*
--------------------------------------------------------------------------------
Define a fastqc for raw_reads function for pipeline
--------------------------------------------------------------------------------
*/
process GET_SOFTWARE_VERSION_FOR_RNAPIPE_ANALYSIS {

   publishDir "${params.outdir}/pipeline_info", mode: 'copy'

   output:
   path ("*.txt"), emit: software_version
   script:
   """
   echo $workflow.manifest.version > v_pipeline.txt
   echo $workflow.nextflow.version > v_nextflow.txt
   fastqc --version > v_fastqc.txt
   echo \$(fastp --version 2>&1) > v_fastp.txt
   hisat2 --version > v_hisat2.txt
   samtools --version > v_samtools.txt
   stringtie --version > v_stringtie.txt
   echo \$(gffread --version 2>&1) > v_gffread.txt
   echo \$(gffcompare --version 2>&1) > v_gffcompare.txt
   salmon --version > v_salmon.txt
   echo \$(R --version 2>&1) > v_R.txt
   multiqc --version > v_multiqc.txt
   """
}

process FASTQC_QUALITY_CHECK_FOR_RAW_READS {
    tag "$sample"
    publishDir "${params.outdir}/raw_fastqc_report", mode: 'copy'
    input:
    tuple val(sample), path (reads)
    output:
    tuple val(sample), path("*.html"), emit: html
    tuple val(sample), path("*.zip") , emit: zip
    script:
    if (params.single_end) {
        """
        fastqc --threads $task.cpus ${reads}       
        """
    } else {
        """
        fastqc --threads $task.cpus ${reads[0]} ${reads[1]}
        """
}
}
/*
--------------------------------------------------------------------------------
Define a fastp for raw_reads function for pipeline
--------------------------------------------------------------------------------
*/
process FASTP_READS_FILTER_FOR_RAW_READS {
    tag "$sample"
    publishDir "${params.outdir}/fastp_report", mode: 'copy'
    input:
    tuple val(sample), path(reads)
    output:
    tuple val(sample), path('*.clean.fq.gz')  , emit:reads
    tuple val(sample), path('*.clean.fq.gz')  , emit:clean_reads_salmon
    tuple val(sample), path('*.clean.fq.gz')  , emit:clean_reads_hisat2
    tuple val(sample), path('*.json')         , emit: json
    tuple val(sample), path('*.html')         , emit: html
    tuple val(sample), path('*.log')          , emit: log
    tuple val(sample), path('*.fail.fq.gz'), optional:true, emit: reads_fail

    script:
    if (params.single_end) {
    """
        fastp \\
            --in1 ${reads} \\
            --out1 ${sample}.clean.fq.gz \\
            --thread $task.cpus \\
            --json ${sample}.fastp.json \\
            --html ${sample}.fastp.html \\
            --failed_out ${sample}.fail.fq.gz \\
            2> ${sample}.fastp.log
    """

    } else {
    """
        fastp \\
            --in1 ${reads[0]} \\
            --in2 ${reads[1]} \\
            --out1 ${sample}_1.clean.fq.gz \\
            --out2 ${sample}_2.clean.fq.gz \\
            --json ${sample}.fastp.json \\
            --html ${sample}.fastp.html \\
            --unpaired1 ${sample}_1.fail.fq.gz \\
            --unpaired2 ${sample}_2.fail.fq.gz \\
            --thread $task.cpus \\
            --detect_adapter_for_pe \\
            2> ${sample}.fastp.log
    """

    }
}

/*
--------------------------------------------------------------------------------
Define a fastqc for clean_reads function for pipeline
--------------------------------------------------------------------------------
*/
process FASTQC_QUALITY_CHECK_FOR_CLEAN_READS {
    tag "$sample"
    publishDir "${params.outdir}/clean_fastqc_report", mode: 'copy'
    input:
    tuple val(sample), path (reads)
    output:
    tuple val(sample), path("*.html"), emit: html
    tuple val(sample), path("*.zip") , emit: zip
    script:
    if (params.single_end) {
        """
        fastqc --threads $task.cpus ${reads}       
        """
    } else {
        """
        fastqc --threads $task.cpus ${reads[0]} ${reads[1]}
        """
}
}
/*
--------------------------------------------------------------------------------
Define a hisat2_mapping function for pipeline
--------------------------------------------------------------------------------
*/
process HISAT2_READS_MAPPING_FOR_CLEAN_READS{
    tag "$sample"
    publishDir "${params.outdir}/hisat2",mode: 'copy'

    input:
    tuple val(sample), path(reads)
    //path index from params.hisat2_index

    output:
    tuple val(sample), path("*.bam") , emit: bam
    tuple val(sample), path("*.log") , emit: summary
    tuple val(sample), path("*fq.gz"), optional:true, emit: fastq

    script:
 
    if (params.single_end) {

        """
        hisat2 \\
            -x $index \\
            -U $reads \\
            --rna-strandness F \\
            --known-splicesite-infile $splicesites \\
            --summary-file ${sample}.hisat2.summary.log \\
            --threads $task.cpus \\
            --un-gz ${sample}.unmapped.fq.gz \\
            $options.args \\
            | samtools view -bS -F 4 -F 256 - > ${sample}.bam

        """
    } else {
       
        """
        hisat2 \\
            -x ${params.hisat2_index} \\
            -1 ${reads[0]} \\
            -2 ${reads[1]} \\
            --met-stderr \\
            --new-summary \\
            --dta \\
            --summary-file ${sample}.hisat2.summary.log \\
            --threads $task.cpus \\
            --un-conc-gz ${sample}.unmapped.fq.gz \\
            --no-mixed \\
            --no-discordant \\
            | samtools view -bS -F 4 -F 8 -F 256 - > ${sample}.bam

        if [ -f ${sample}.unmapped.fq.1.gz ]; then
            mv ${sample}.unmapped.fq.1.gz ${sample}.unmapped_1.fq.gz
        fi
        if [ -f ${sample}.unmapped.fq.2.gz ]; then
            mv ${sample}.unmapped.fq.2.gz ${sample}.unmapped_2.fq.gz
        fi

        """
    }

}

/*
--------------------------------------------------------------------------------
Define a bam sort function for pipeline
--------------------------------------------------------------------------------
*/

process SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM{
    tag "$sample"
    input:
    tuple val(sample), path (bam)
    output:
    tuple val(sample), path("*.sorted.bam") , emit:sorted_bam

    script:
    """
    samtools sort -@ $task.cpus -o ${sample}.sorted.bam -T $sample $bam
    """

}
/*
--------------------------------------------------------------------------------
Define a bam index function for pipeline
--------------------------------------------------------------------------------
*/
process SAMTOOLS_INDEX_FOR_HISAT2_MAPPED_BAM {
    tag "$sample"
    publishDir "${params.outdir}/bam_report/idx_statistics",mode: 'copy'

    input:
    tuple val(sample), path (bam)

    output:
    tuple val(sample), path("*.idxstats"), emit: idxstats

    script:

    """
    samtools index $bam
    samtools idxstats $bam > ${bam}.idxstats

    """
}
/*
--------------------------------------------------------------------------------
Define a bam stat function for pipeline
--------------------------------------------------------------------------------
*/
process SAMTOOLS_STAT_FOR_HISAT2_MAPPED_BAM{
    tag "$sample"
    publishDir "${params.outdir}/bam_report/statistics",mode: 'copy'

    input:
    tuple val(sample), path (bam)

    output:
    tuple val(sample), path("*.stats"), emit: stats

    script:

    """
    samtools stats $bam > ${bam}.stats

    """
}
/*
--------------------------------------------------------------------------------
Define a bam flagstat function for pipeline
--------------------------------------------------------------------------------
*/
process SAMTOOLS_FLAGSTAT_FOR_HISAT2_MAPPED_BAM{
    tag "$sample"
    publishDir "${params.outdir}/bam_report/flag_statistics",mode: 'copy'

    input:
    tuple val(sample), path (bam)

    output:

    tuple val(sample), path("*.flagstat"), emit: flagstat

    script:

    """
    samtools flagstat $bam > ${bam}.flagstat

    """
}
/*
--------------------------------------------------------------------------------
Define a stringtie assemble function for pipeline
--------------------------------------------------------------------------------
*/
process STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM{
    tag "$sample"
    publishDir "${params.outdir}/stringtie_assemble",mode: 'copy'

    input:
    tuple val(sample), path (bam)
    path gtf
    output:
    path ("*.transcripts.gtf") , emit: stringtie_gtf
    tuple val(sample), path("*.genes_abundance.txt"), emit: stringtie_genes_abundance
    tuple val(sample), path("*.ballgown"), emit: stringtie_ballgown
    tuple val(sample), path("*.coverage.gtf"), emit: stringtie_coverage_gtf

    script:

    """
    stringtie \\
        -p $task.cpus \\
        -G $gtf \\
        -o ${sample}.transcripts.gtf \\
        $bam \\
        -v \\
        -A ${sample}.genes_abundance.txt \\
        -C ${sample}.coverage.gtf \\
        -b ${sample}.ballgown
    """  

}
/*
--------------------------------------------------------------------------------
Define a stringtie trans merge function for pipeline
--------------------------------------------------------------------------------
*/
process STRINGTIE_MERGE_TRANSCRIPTS_GTF_FILE_FOR_ALL_SAMPLE{
    publishDir "${params.outdir}/stringtie_merge",mode: 'copy'

    input:
    path gtf
    file gtf_filenames
    output:
    path ("stringtie_merged.gtf") , emit: stringtie_merged_gtf
    script:
    """
    stringtie --merge \\
        -p $task.cpu \\
        -G $gtf \\
        -o stringtie_merged.gtf \\
        $gtf_filenames  

    """
}
/*
--------------------------------------------------------------------------------
Define a gffcompare function for pipeline
--------------------------------------------------------------------------------
*/
process GFF_COMPARE_FOR_MERGED_NEW_GTF_WITH_REFERENCE_GTF_FILE {
    publishDir "${params.outdir}/gffcompare",mode: 'copy'
    input:
    path transcripts_gtf 
    path gtf
    output:
    path("*stringtie_merged.gtf.tmap") , emit:gffcmp_tmap
    path("gffcmp*") , emit: gffcmp_results
    script:
    """
    gffcompare -R \\
        -r $gtf \\
        $transcripts_gtf > log.txt  
    """
}
/*
--------------------------------------------------------------------------------
Define a tmap to gtf  function for pipeline
--------------------------------------------------------------------------------
*/
process CONVERT_GFFCOMPARE_TMAP_TO_NOVEL_LNCRNA_GTF_AND_FASTA{
    publishDir "${params.outdir}/potential_lncRNA",mode: 'copy'
    input:
    path tmap 
    path merged_gtf
    output:
    path ("novel.longRNA.fa") , emit: potential_lncRNA
    path ("novel.longRNA.*")  , emit: lncRNA_predict_results
    script:
    """
    awk '\$3 =="x"||\$3=="u"||\$3=="i"{print \$0}' $tmap > novel.gtf.tmap
    #   excluding length smaller than 200 nt
    awk '\$10 >200{print}' novel.gtf.tmap > novel.longRNA.gtf.tmap
    #   extract gtf
    awk '{print \$5}' novel.longRNA.gtf.tmap |perl ${baseDir}/bin/extract_gtf_by_name.pl ${merged_gtf} - >novel.longRNA.gtf
    awk '{if(\$3=="exon"){print \$0}}' novel.longRNA.gtf > novel.longRNA.format.gtf 
    # get fasta from gtf
    gffread novel.longRNA.gtf -g ${genome_fasta} -w novel.longRNA.fa.tmp -W
    awk '{ if(/^>/){print \$1}else{print \$0}}' novel.longRNA.fa.tmp > novel.longRNA.fa 

    """
}
/*
--------------------------------------------------------------------------------
Define some salmon index and quant function for pipeline
--------------------------------------------------------------------------------
*/
process SALMON_QUANT_FOR_CLEAN_READS_WITH_SPECIFIED_SALMON_INDEX{
    tag "${sample}"
    publishDir "${params.outdir}/salmon_quant",mode: 'copy'

    input:
    tuple val(sample), path (reads) 
    path  index 
    path  gtf 
    output:
    tuple val(sample), path("${sample}") ,emit:results
    script:
    def input_reads = params.single_end ? "-r $reads" : "-1 ${reads[0]} -2 ${reads[1]}"
    """
    salmon quant \\
        --geneMap $gtf \\
        --threads $task.cpus \\
        --index $index \\
        $input_reads\\
        -o $sample

    """
}

process PREPARE_SALMON_QUANT_INDEX_WITH_GENOME_FASTA_AND_GTF{

    publishDir "${params.outdir}/salmon_index",mode: 'copy'
    input:
    path gtf 
    path genome 
    output:
    path "salmon" ,emit:index
    script:
    """
    gffread \\
    -w transcripts.fa.tmp \\
    -g ${genome} \\
    $gtf
    ###handle the format of input files required by salmon index building
    grep '^>' ${genome} | cut -d ' ' -f 1 > decoys.txt
    awk '{ if(/^>/){print \$1}else{print \$0}}' transcripts.fa.tmp > salmon_input_transcripts.fa
    cat salmon_input_transcripts.fa ${genome} > gentrome.fa
    ###############
    salmon index -t gentrome.fa -i salmon

    """
}

process SALMON_QUANT_FOR_CLEAN_READS_WITH_PREVIOUS_BUILD_INDEX{
    tag "${sample}"
    publishDir "${params.outdir}/salmon_quant",mode: 'copy'

    input:
    tuple val(sample), path (reads)
    path  index
    path gtf 
    output:
    tuple val(sample),path ("${sample}") , emit:results
    script:
    def strandedness = params.single_end ? 'U' : 'IU'
    def input_reads = params.single_end ? "-r $reads" : "-1 ${reads[0]} -2 ${reads[1]}"
    """
    salmon quant \\
        --geneMap $gtf \\
        --threads $task.cpus \\
        --libType=$strandedness \\
        --index $index \\
        $input_reads\\
        -o $sample

    """
}

process MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX{

    publishDir "${params.outdir}/salmon_report",mode: 'copy'
    input:
    path ("salmon/*")
    output:
    path ("genes_counts_salmon.tsv") ,           emit: salmon_merge_gene_counts
    path ("genes_tpm_salmon.tsv") ,            emit: salmon_merge_gene_abundance
    path ("transcripts_counts_salmon.tsv") ,   emit: salmon_merge_transcirpts_counts
    path ("transcripts_tpm_salmon.tsv") ,      emit: salmon_merge_transcirpts_tpm
    path ("transcripts_length_salmon.tsv") ,   emit: transcripts_length_salmon
    path ("transcripts_elen_salmon.tsv") ,     emit: transcripts_elen_salmon
    path ("genes_length_salmon.tsv") ,         emit: genes_length_salmon
    path ("genes_elen_salmon.tsv") ,           emit: genes_elen_salmon
    script: 

    """
    salmon quantmerge --quants salmon/* --column tpm -o transcripts_tpm_salmon.tsv
    salmon quantmerge --quants salmon/* --column numreads -o transcripts_counts_salmon.tsv
    salmon quantmerge --quants salmon/* --column len -o transcripts_length_salmon.tsv
    salmon quantmerge --quants salmon/* --column elen -o transcripts_elen_salmon.tsv
    salmon quantmerge --quants salmon/* --genes --column tpm -o genes_tpm_salmon.tsv
    salmon quantmerge --quants salmon/* --genes --column numreads -o genes_counts_salmon.tsv
    salmon quantmerge --quants salmon/* --genes --column len -o genes_length_salmon.tsv
    salmon quantmerge --quants salmon/* --genes --column elen -o genes_elen_salmon.tsv 
    """
}
/*
--------------------------------------------------------------------------------
Define some multiqc report function for pipeline
--------------------------------------------------------------------------------
*/
process MULTIQC_FOR_RAW_READS_FASTQC_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/raw_reads_fastqc", mode: 'copy'

    input:
    path ('fastqc/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastqc/
    """
}

process MULTIQC_FOR_FASTP_READS_FILTER_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/fastp", mode: 'copy'

    input:
    path ('fastp/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastp/
    """
}

process MULTIQC_FOR_CLEAN_READS_FASTQC_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/raw_reads_fastqc", mode: 'copy'

    input:
    path ('fastqc/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export fastqc/
    """
}

process MULTIQC_FOR_HISAT2_MAPPING_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/hisat2_mapping", mode: 'copy'

    input:
    path ('hisat2/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export hisat2/
    """
}

process MULTIQC_FOR_SAMTOOLS_STATISTICS_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/samtools_stat", mode: 'copy'

    input:
    path ('samtools_stat/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export samtools_stat/
    """
}

process MULTIQC_FOR_SAMTOOLS_FLAG_STATISTICS_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/samtools_flagstat", mode: 'copy'

    input:
    path ('samtools_flagstat/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export samtools_flagstat/
    """
}

process MULTIQC_FOR_SAMTOOLS_IDX_STATISTICS_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/samtools_idxstat", mode: 'copy'

    input:
    path ('samtools_idxstat/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export samtools_idxstat/
    """
}

process MULTIQC_FOR_SALMON_QUANT_RESULTS {
    label 'process_medium'
    publishDir "${params.outdir}/Analysis_Report/salmon_quant", mode: 'copy'

    input:
    path ('salmon_quant/*')
    
    output:
    path "*multiqc_report.html", emit: report
    path "*_data"              , emit: data
    path "*_plots"             , optional:true, emit: plots

    script:
    """
    multiqc -f --export salmon_quant/
    """
}

/*================================================================================
            Define workflow functions for RNAseq pipeline
--------------------------------------------------------------------------------
==================================================================================
*/

/*
--------------------------------------------------------------------------------
Define a fastqc/fastp reads check and filter function for pipeline
--------------------------------------------------------------------------------
*/
workflow FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS {
    take:
    reads         // channel: [ val(meta), [ reads ] ]
    main:

    raw_fastqc_html    = Channel.empty()
    raw_fastqc_zip     = Channel.empty()

    FASTQC_QUALITY_CHECK_FOR_RAW_READS ( reads ).html.set { raw_fastqc_html }
    raw_fastqc_zip     = FASTQC_QUALITY_CHECK_FOR_RAW_READS.out.zip


    fastp_reads        = reads
    fastp_log          = Channel.empty()
    fastp_json         = Channel.empty()
    fastp_html         = Channel.empty()

  /**  trim_reads = umi_reads
    trim_html  = Channel.empty()
    trim_zip   = Channel.empty()
    trim_log   = Channel.empty()
    trimgalore_version = Channel.empty()*/

    FASTP_READS_FILTER_FOR_RAW_READS ( fastp_reads ).reads.set { clean_reads }
    fastp_html  = FASTP_READS_FILTER_FOR_RAW_READS.out.html
    fastp_json  = FASTP_READS_FILTER_FOR_RAW_READS.out.json
    fastp_log   = FASTP_READS_FILTER_FOR_RAW_READS.out.log


    clean_fastqc_html    = Channel.empty()
    clean_fastqc_zip     = Channel.empty()

    FASTQC_QUALITY_CHECK_FOR_CLEAN_READS ( clean_reads ).html.set { clean_fastqc_html }
    clean_fastqc_zip     = FASTQC_QUALITY_CHECK_FOR_CLEAN_READS.out.zip

    emit:
    clean_reads_ch     = clean_reads
    clean_reads_salmon = clean_reads
    clean_reads_hisat2 = clean_reads
    raw_fastqc_html     //
    clean_fastqc_html   //
    raw_fastqc_zip
    clean_fastqc_zip         // channel: [ val(meta), [ zip ] ]
    fastp_html
    fastp_log          // channel: [ val(meta), [ html ] ]
    fastp_json           // channel: [ val(meta), [ zip ] ]

}
/*
--------------------------------------------------------------------------------
Define a hisat2/samtools bam mapping and stat function for pipeline
--------------------------------------------------------------------------------
*/
workflow HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM{

    take:
    reads
    main:

    HISAT2_READS_MAPPING_FOR_CLEAN_READS ( reads )
    SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM ( HISAT2_READS_MAPPING_FOR_CLEAN_READS.out.bam )
    bam_for_stat      = SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM.out.sorted_bam
    bam_for_flagstat  = SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM.out.sorted_bam
    bam_for_idxstat   = SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM.out.sorted_bam
    SAMTOOLS_INDEX_FOR_HISAT2_MAPPED_BAM ( bam_for_idxstat )
    SAMTOOLS_STAT_FOR_HISAT2_MAPPED_BAM ( bam_for_stat )
    SAMTOOLS_FLAGSTAT_FOR_HISAT2_MAPPED_BAM ( bam_for_flagstat )

    emit:
    sorted_bam_samtools = SAMTOOLS_SORTING_BAM_FOR_HISAT2_UNSORTED_BAM.out.sorted_bam
    stats               = SAMTOOLS_STAT_FOR_HISAT2_MAPPED_BAM.out.stats
    idxstats            = SAMTOOLS_INDEX_FOR_HISAT2_MAPPED_BAM.out.idxstats
    flagstat            = SAMTOOLS_FLAGSTAT_FOR_HISAT2_MAPPED_BAM.out.flagstat
    summary             = HISAT2_READS_MAPPING_FOR_CLEAN_READS.out.summary
}
/*
--------------------------------------------------------------------------------
Define a stringtie assemble/merge/gffcmp/extract_lncrna_fasta function for pipeline
--------------------------------------------------------------------------------
*/

workflow STRINGTIE_ASSEMBLE_PIPELINE_AND_GATHER_STRINGTIE_ASSEMBLED_GTF_DIR{
    take:
    bam
    gtf
    main:

    STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM ( bam, gtf )
    STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM.out.stringtie_gtf.collectFile(name: 'merge_list.txt', newLine: true)
                                                                .set { GTFfilenames }
    STRINGTIE_MERGE_TRANSCRIPTS_GTF_FILE_FOR_ALL_SAMPLE ( gtf, GTFfilenames )
    GFF_COMPARE_FOR_MERGED_NEW_GTF_WITH_REFERENCE_GTF_FILE ( STRINGTIE_MERGE_TRANSCRIPTS_GTF_FILE_FOR_ALL_SAMPLE.out.stringtie_merged_gtf, gtf )
    CONVERT_GFFCOMPARE_TMAP_TO_NOVEL_LNCRNA_GTF_AND_FASTA ( GFF_COMPARE_FOR_MERGED_NEW_GTF_WITH_REFERENCE_GTF_FILE.out.gffcmp_tmap,  STRINGTIE_MERGE_TRANSCRIPTS_GTF_FILE_FOR_ALL_SAMPLE.out.stringtie_merged_gtf)                                                          
    
    emit:
    stringtie_gtf               = STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM.out.stringtie_gtf
    stringtie_genes_abundance   = STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM.out.stringtie_genes_abundance
    stringtie_ballgown          = STRINGTIE_ASSEMBLE_FOR_SORTED_SAMTOOLS_BAM.out.stringtie_ballgown
    stringtie_merged_gtf        = STRINGTIE_MERGE_TRANSCRIPTS_GTF_FILE_FOR_ALL_SAMPLE.out.stringtie_merged_gtf
    gffcmp_tmap                 = GFF_COMPARE_FOR_MERGED_NEW_GTF_WITH_REFERENCE_GTF_FILE.out.gffcmp_tmap
    potential_lncRNA_fasta      = CONVERT_GFFCOMPARE_TMAP_TO_NOVEL_LNCRNA_GTF_AND_FASTA.out.potential_lncRNA
}

/*
--------------------------------------------------------------------------------
Define a salmon index/quant/merge function for pipeline
--------------------------------------------------------------------------------
*/

workflow SALMON_BUILD_INDEX_QUANT_AND_MERGE_FOR_CLEAN_READS{
    take:
    genome
    gtf
    index
    reads

    main:

    if (params.salmon_index){
        SALMON_QUANT_FOR_CLEAN_READS_WITH_SPECIFIED_SALMON_INDEX( reads, params.salmon_index, gtf )
        MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX ( SALMON_QUANT_FOR_CLEAN_READS_WITH_SPECIFIED_SALMON_INDEX.out.results)
    } else {
        
        PREPARE_SALMON_QUANT_INDEX_WITH_GENOME_FASTA_AND_GTF( gtf, genome )
        SALMON_QUANT_FOR_CLEAN_READS_WITH_PREVIOUS_BUILD_INDEX( reads, PREPARE_SALMON_QUANT_INDEX_WITH_GENOME_FASTA_AND_GTF.out.index, gtf )
        MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX( SALMON_QUANT_FOR_CLEAN_READS_WITH_PREVIOUS_BUILD_INDEX.out.results.collect{it[1]} )
    }
    emit:
    salmon_index                    = PREPARE_SALMON_QUANT_INDEX_WITH_GENOME_FASTA_AND_GTF.out.index
    salmon_quantmerge_results       = SALMON_QUANT_FOR_CLEAN_READS_WITH_PREVIOUS_BUILD_INDEX.out.results
    salmon_merge_gene_counts        = MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX.out.salmon_merge_gene_counts
    salmon_merge_gene_abundance     = MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX.out.salmon_merge_gene_abundance
    salmon_merge_transcirpts_counts = MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX.out.salmon_merge_transcirpts_counts
    salmon_merge_transcirpts_tpm    = MERGE_SALMON_QUANT_RESULT_TO_SALMON_GENE_AND_TRANSCRIPTS_MATRIX.out.salmon_merge_transcirpts_tpm
}

/*
--------------------------------------------------------------------------------
Define a MULTIQC REPORT function for pipeline
--------------------------------------------------------------------------------
*/
workflow MULTIQC_REPORT_FOR_ALL_ANALYSIS_RESULTS {

    take:
    raw_reads_fastqc_zip
    fastq_results 
    clean_reads_fastqc_zip
    hisat2_mapping_summary
    samtools_stat_results
    samtools_flagstat_results
    samtools_idxstat_results
    salmon_quant_resutls

    main:
    MULTIQC_FOR_RAW_READS_FASTQC_RESULTS ( raw_reads_fastqc_zip )
    MULTIQC_FOR_FASTP_READS_FILTER_RESULTS ( fastq_results )
    MULTIQC_FOR_CLEAN_READS_FASTQC_RESULTS ( clean_reads_fastqc_zip )
    MULTIQC_FOR_HISAT2_MAPPING_RESULTS ( hisat2_mapping_summary )
    MULTIQC_FOR_SAMTOOLS_STATISTICS_RESULTS ( samtools_stat_results )
    MULTIQC_FOR_SAMTOOLS_FLAG_STATISTICS_RESULTS ( samtools_flagstat_results )
    MULTIQC_FOR_SAMTOOLS_IDX_STATISTICS_RESULTS ( samtools_idxstat_results )
    MULTIQC_FOR_SALMON_QUANT_RESULTS ( salmon_quant_resutls )
}

/*================================================================================
            THIS IS THE START OF THE PIPELINE
--------------------------------------------------------------------------------
==================================================================================
*/

workflow {
    GET_SOFTWARE_VERSION_FOR_RNAPIPE_ANALYSIS (  )

    FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS ( raw_reads )

    HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM ( FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.clean_reads_hisat2 )

    STRINGTIE_ASSEMBLE_PIPELINE_AND_GATHER_STRINGTIE_ASSEMBLED_GTF_DIR ( HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM.out.sorted_bam_samtools , gtf )

    SALMON_BUILD_INDEX_QUANT_AND_MERGE_FOR_CLEAN_READS ( genome_fasta, gtf, params.salmon_index, FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.clean_reads_salmon )

    MULTIQC_REPORT_FOR_ALL_ANALYSIS_RESULTS(
        FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.raw_fastqc_zip.collect{it[1]},
        FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.fastp_json.collect{it[1]},
        FASTQC_QUALITY_CHECK_AND_FASTP_READS_FILTER_FOR_RAW_READS.out.clean_fastqc_zip.collect{it[1]},
        HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM.out.summary.collect{it[1]},
        HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM.out.stats.collect{it[1]},
        HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM.out.flagstat.collect{it[1]},
        HISAT_MAPPING_FOR_CLEAN_READS_AND_SAMTOOLS_SORT_AND_STATISTICS_FOR_MAPPED_BAM.out.idxstats.collect{it[1]},
        SALMON_BUILD_INDEX_QUANT_AND_MERGE_FOR_CLEAN_READS.out.salmon_quantmerge_results.collect{it[1]}

        )
}









    
